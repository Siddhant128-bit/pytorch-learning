{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'> Pytorch Work Flow </h2>\n",
    "\n",
    "<p> In this portion of the repository we will learn how ML pipelines can be built on pytorch.<br> The idea of Machine Learning / Deep Learning systems is that we use data from the past train the model to understand the patterns and predict future data. <br> The image below shows the building of AI sytems.</p>\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png'>\n",
    "\n",
    "<p> The table below shows different steps of the process: </p>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Topic</th>\n",
    "    <th>Contents</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1. Getting data ready</td>\n",
    "    <td>Data can be almost anything but to get started we're going to create a simple straight line</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2. Building a model</td>\n",
    "    <td>Here we'll create a model to learn patterns in the data, we'll also choose a loss function, optimizer and build a training loop.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3. Fitting the model to data (training)</td>\n",
    "    <td>We've got data and a model, now let's let the model (try to) find patterns in the (training) data.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4. Making predictions and evaluating a model (inference)</td>\n",
    "    <td>Our model's found patterns in the data, let's compare its findings to the actual (testing) data.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5. Saving and loading a model</td>\n",
    "    <td>You may want to use your model elsewhere, or come back to it later, here we'll cover that.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6. Putting it all together</td>\n",
    "    <td>Let's take all of the above and combine it.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<p> Most of the original content for this notebook can be found <a href='https://www.learnpytorch.io/01_pytorch_workflow/'>here</a> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preperation </h3>\n",
    "\n",
    "Here we are synthesizing data with x ranging from 0-1 with step of 0.01. We are doing Linear Regression so <br> slope=weight_known_initial=0.45 bias_known_initial=intecept=0.33<br>\n",
    "Hence <br>\n",
    "Y=M*X+C [M=weight,C=bias ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0.0, 0.009999999776482582, 0.019999999552965164, 0.029999999329447746, 0.03999999910593033, 0.05000000074505806, 0.05999999865889549, 0.07000000029802322, 0.07999999821186066, 0.08999999612569809, 0.10000000149011612, 0.10999999940395355, 0.11999999731779099, 0.12999999523162842, 0.14000000059604645, 0.14999999105930328, 0.1599999964237213, 0.17000000178813934, 0.17999999225139618, 0.1899999976158142, 0.20000000298023224, 0.20999999344348907, 0.2199999988079071, 0.22999998927116394, 0.23999999463558197, 0.25, 0.25999999046325684, 0.26999998092651367, 0.2800000011920929, 0.28999999165534973, 0.29999998211860657, 0.3100000023841858, 0.3199999928474426, 0.32999998331069946, 0.3400000035762787, 0.3499999940395355, 0.35999998450279236, 0.3700000047683716, 0.3799999952316284, 0.38999998569488525, 0.4000000059604645, 0.4099999964237213, 0.42000001668930054, 0.4300000071525574, 0.4399999976158142, 0.45000001788139343, 0.46000000834465027, 0.4699999988079071, 0.47999998927116394, 0.4899999797344208, 0.5, 0.5099999904632568, 0.5199999809265137, 0.5299999713897705, 0.5399999618530273, 0.550000011920929, 0.5600000023841858, 0.5699999928474426, 0.5799999833106995, 0.5899999737739563, 0.6000000238418579, 0.6100000143051147, 0.6200000047683716, 0.6299999952316284, 0.6399999856948853, 0.6499999761581421, 0.6599999666213989, 0.6699999570846558, 0.6800000071525574, 0.6899999976158142, 0.699999988079071, 0.7099999785423279, 0.7200000286102295, 0.7300000190734863, 0.7400000095367432, 0.75, 0.7600000500679016, 0.7700000405311584, 0.7800000309944153, 0.7900000214576721, 0.800000011920929, 0.8100000023841858, 0.8199999928474426, 0.8299999833106995, 0.8400000333786011, 0.8500000238418579, 0.8600000143051147, 0.8700000047683716, 0.8799999952316284, 0.8899999856948853, 0.8999999761581421, 0.9099999666213989, 0.9200000166893005, 0.9300000071525574, 0.9399999976158142, 0.949999988079071, 0.9599999785423279, 0.9700000286102295, 0.9800000190734863, 0.9900000095367432] \n",
      "Y: [0.33000001311302185, 0.3345000147819519, 0.33900001645088196, 0.343500018119812, 0.34800001978874207, 0.3525000214576721, 0.3570000231266022, 0.3615000247955322, 0.3659999966621399, 0.37049999833106995, 0.375, 0.37950000166893005, 0.3840000033378601, 0.38850000500679016, 0.3930000066757202, 0.39750000834465027, 0.4020000100135803, 0.4065000116825104, 0.41100001335144043, 0.4155000150203705, 0.42000001668930054, 0.4245000183582306, 0.42900002002716064, 0.4334999918937683, 0.43800002336502075, 0.4424999952316284, 0.44699999690055847, 0.4514999985694885, 0.45600003004074097, 0.46050000190734863, 0.4650000035762787, 0.46950000524520874, 0.4740000069141388, 0.47850000858306885, 0.4830000102519989, 0.48750001192092896, 0.4919999837875366, 0.49650001525878906, 0.5009999871253967, 0.5055000185966492, 0.5099999904632568, 0.5145000219345093, 0.5189999938011169, 0.5235000252723694, 0.527999997138977, 0.5325000286102295, 0.5370000004768372, 0.5414999723434448, 0.5460000038146973, 0.5505000352859497, 0.5550000071525574, 0.559499979019165, 0.5640000104904175, 0.5684999823570251, 0.5729999542236328, 0.5774999856948853, 0.5820000171661377, 0.5864999890327454, 0.590999960899353, 0.5954999923706055, 0.6000000238418579, 0.6045000553131104, 0.6089999675750732, 0.6134999990463257, 0.6180000305175781, 0.6225000023841858, 0.6269999742507935, 0.6315000057220459, 0.6360000371932983, 0.640500009059906, 0.6449999809265137, 0.6495000123977661, 0.6540000438690186, 0.6585000157356262, 0.6629999876022339, 0.6675000190734863, 0.6720000505447388, 0.6765000224113464, 0.6809999942779541, 0.6855000257492065, 0.6899999976158142, 0.6944999694824219, 0.6990000009536743, 0.7035000324249268, 0.7080000042915344, 0.7124999761581421, 0.7170000076293945, 0.721500039100647, 0.7260000109672546, 0.7304999828338623, 0.7350000143051147, 0.7394999861717224, 0.7440000176429749, 0.7484999895095825, 0.753000020980835, 0.7574999928474426, 0.7619999647140503, 0.7664999961853027, 0.7710000276565552, 0.7754999995231628]\n"
     ]
    }
   ],
   "source": [
    "#Ground truth\n",
    "weight_known_initial=0.45\n",
    "bias_known_initial=0.33\n",
    "\n",
    "#Data synthesis \n",
    "x=torch.arange(0,1,0.01)\n",
    "y=weight_known_initial*x+bias_known_initial\n",
    "print(f'X: {x.tolist()} \\nY: {y.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Splitting Data </h4>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Split</th>\n",
    "    <th>Purpose</th>\n",
    "    <th>Amount of total data</th>\n",
    "    <th>How often is it used?</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Training set</td>\n",
    "    <td>The model learns from this data (like the course materials you study during the semester).</td>\n",
    "    <td>~60-80%</td>\n",
    "    <td>Always</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Validation set</td>\n",
    "    <td>The model gets tuned on this data (like the practice exam you take before the final exam).</td>\n",
    "    <td>~10-20%</td>\n",
    "    <td>Often but not always</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Testing set</td>\n",
    "    <td>The model gets evaluated on this data to test what it has learned (like the final exam you take at the end of the semester).</td>\n",
    "    <td>~10-20%</td>\n",
    "    <td>Always</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<p> Here we are going to split to train and test no validation split </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: 80\n",
      "Train Y: 80\n",
      "Test X: 20\n",
      "Test Y: 20\n"
     ]
    }
   ],
   "source": [
    "train_length=int(0.8*len(x))\n",
    "x_train,y_train=x[:train_length],y[:train_length]\n",
    "x_test,y_test=x[train_length:],y[train_length:]\n",
    "\n",
    "print(f'Train X: {len(x_train)}\\nTrain Y: {len(y_train)}\\nTest X: {len(x_test)}\\nTest Y: {len(y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
