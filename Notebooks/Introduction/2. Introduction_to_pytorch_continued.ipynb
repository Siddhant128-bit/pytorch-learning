{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tensor Data types </h3>\n",
    "\n",
    "Tensors are pretty confusing to deal with at first because there are many different types of tensor datatypes in pytorch <br>\n",
    "Some are specific to CPU other are better for GPU <br>\n",
    "\n",
    "Tensors also have bits as torch.float32 torch.float16 torch.float8 and so on.<br>\n",
    "In simplest understanding term we can understand that higher bit or precision value means more detail can be obtained and carried over <br>\n",
    "but are comparatively slower then lower precision value <br>\n",
    "\n",
    "Some major issues we come across while handling tensors are: \n",
    "<ol>\n",
    "    <li> datatype issue where the 2 tensors won't have same datatype format (float32 and float16) </li>\n",
    "    <li> device issue where the tensor is deisgned to work on CPU and other is designated to work for GPU </li>\n",
    "</ol>\n",
    "\n",
    "Below we can observe different tensor types with precision values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3246, 0.5534, 0.1123]) torch.float32 cpu\n",
      "tensor([0.3245, 0.5532, 0.1124], dtype=torch.float16) torch.float16 cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "float_32_tensor=torch.tensor([0.3245671892,0.55341245,0.11234153],dtype=torch.float32,device=None,requires_grad=False)\n",
    "print(float_32_tensor,float_32_tensor.dtype,float_32_tensor.device)\n",
    "\n",
    "float_16_tensor=torch.tensor([0.3245671892,0.55341245,0.11234153],dtype=torch.float16,device=None,requires_grad=False)\n",
    "print(float_16_tensor,float_16_tensor.dtype,float_16_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Matrix Multiplication </h3>\n",
    "\n",
    "We can easily say that matrix multiplication is the backbone of neural network architechture, <br>\n",
    "Since we have multiple  neurons with their own weights and biases resulting in structures having alot of outputs with many more operations which be optimized by using matrix multiplication<br>\n",
    "<br>\n",
    "PyTorch implements matrix multiplication functionality in the torch.matmul() or torch.mm() method.\n",
    "\n",
    "<h4> Rule for Matrix Multiplication: </h4>\n",
    "<img width=800 height=500 src='https://i.ytimg.com/vi/M5TsRZt3mis/maxresdefault.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matirx A: \n",
      " tensor([[2., 1.],\n",
      "        [1., 2.]]) \n",
      " Dimension of Matrix A: \n",
      " torch.Size([2, 2])\n",
      "\n",
      "\n",
      "\n",
      "Matirx B: \n",
      " tensor([[3., 1., 5.],\n",
      "        [2., 2., 3.]]) \n",
      " Dimension of Matrix B: \n",
      " torch.Size([2, 3])\n",
      "\n",
      "\n",
      "\n",
      "Output Matrix: \n",
      " tensor([[ 8.,  4., 13.],\n",
      "        [ 7.,  5., 11.]])\n",
      " Dimension of Output Matrix: \n",
      " torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "Matrix_A=torch.tensor(np.asarray([[2,1],\n",
    "                                [1,2]]),dtype=torch.float32)\n",
    "\n",
    "Matrix_B=torch.tensor(np.asarray([[3,1,5],\n",
    "                                  [2,2,3]]),dtype=torch.float32)\n",
    "\n",
    "print(f'Matirx A: \\n {Matrix_A} \\n Dimension of Matrix A: \\n {Matrix_A.shape}')\n",
    "print('\\n\\n')\n",
    "print(f'Matirx B: \\n {Matrix_B} \\n Dimension of Matrix B: \\n {Matrix_B.shape}')\n",
    "print('\\n\\n')\n",
    "\n",
    "Output_Matrix=torch.matmul(Matrix_A,Matrix_B)\n",
    "print(f'Output Matrix: \\n {Output_Matrix}\\n Dimension of Output Matrix: \\n {Output_Matrix.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Transpose of Matrix </h3>\n",
    "\n",
    "<p>Transpose of a matrix is one of the most commonly used methods in matrix transformation. For a given matrix, the transpose of a matrix is obtained by interchanging rows into columns or columns to rows. <br> It can be done for purpose of preparing matrix for matrix multiplication, finding out inverse of a matrix and many more. </p>\n",
    "\n",
    "<img  align='left' height=300 width=800 src='https://cdn1.byjus.com/wp-content/uploads/2021/09/Important-Questions-for-Class-10-Maths-Chapter-8-Introduction-to-Trigonometry-1.png'>\n",
    "\n",
    "<p>\n",
    "    &nbsp;&nbsp;Matrix Tranpose can be done on pytorch with<br>\n",
    "    <ol>\n",
    "        <li> 1.  ''' torch.tranpose(input,dim0,dim1) ''' : where input is desired tensor to tranpose and dim0 and dim1 are the dimension to be swapped.</li><br>\n",
    "        <li> 2.  ''' tensor.T ''' : where tensor is the desired tensor to tranpose.</li>\n",
    "    <ol>\n",
    "</p>\n",
    "<br><br><br><br><br><br>\n",
    "<h4 align='left'> Example</h4>\n",
    " Assuming we have a matrix A as shown in the figure above: <br>\n",
    " A=[[1,2,3],<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    [4,5,6]]\n",
    "<br><br>\n",
    "B=[[7,8], <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "   [9,10]]\n",
    "\n",
    "As it stands right now A has dimensions as: 2x3 and B has dimensions as: 2x2 \n",
    "right now the 2 cannot be multiplied. Solve it: \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      "\n",
      "Dimensions: torch.Size([2, 3]) \n",
      "--------------------------------------------------\n",
      "Matrix A Transposed:\n",
      " tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]]) \n",
      "\n",
      "Dimensions: torch.Size([3, 2])\n",
      "--------------------------------------------------\n",
      "Matrix Multiplication Output:\n",
      " tensor([[43., 48.],\n",
      "        [59., 66.],\n",
      "        [75., 84.]]) \n",
      "\n",
      " Dimension of Output: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor(np.asarray([[1,2,3],\n",
    "                           [4,5,6]]),dtype=torch.float32,device=None, requires_grad=False)\n",
    "\n",
    "print(f'Matrix A:\\n {A} \\n\\nDimensions: {A.shape} ')\n",
    "\n",
    "#Getting Transpose to change dimensions from 2,3 to 3,2 which makes it possible to have matrix multplication with B having 2x2 resulting in output of 3,2 dimension\n",
    "A=A.T\n",
    "\n",
    "print('-'*50)\n",
    "print(f'Matrix A Transposed:\\n {A} \\n\\nDimensions: {A.shape}')\n",
    "print('-'*50)\n",
    "\n",
    "B=torch.tensor(np.asarray([[7,8],\n",
    "                            [9,10]]),dtype=torch.float32,device=None,requires_grad=False)\n",
    "\n",
    "output=torch.matmul(A,B)\n",
    "\n",
    "print(f'Matrix Multiplication Output:\\n {output} \\n\\n Dimension of Output: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converting Numpy array to Tensor and viceversa </h3>\n",
    "We can convert numpy arrays to tensors and also viceversa with syntax as: \n",
    "<ul>\n",
    "    <li> ''' torch.from_numpy(numpy_arr) ''' : Converts numpy array to tensors </li>\n",
    "    <li> ''' tensor_to_convert.numpy() ''' : The output of this gives numpy array from tensor </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Found: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Numpy Conerted: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Numpy Two: [1 2 3 4 5 6 7 8 9]\n",
      "Tensor Converted: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "tensor_one=torch.ones(10)\n",
    "numpy_one_arr=tensor_one.numpy()\n",
    "\n",
    "print(f'Tensor Found: {tensor_one}\\n')\n",
    "print(f'Numpy Conerted: {numpy_one_arr}')\n",
    "\n",
    "numpy_two_arr=np.arange(1,10)\n",
    "print(f'Numpy Two: {numpy_two_arr}')\n",
    "print(f'Tensor Converted: {torch.from_numpy(numpy_two_arr).type(torch.float32)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Coding questions for Tensors and basics pytorch </h3>\n",
    "\n",
    "Till here most of the basics of pytorch and tensors have been covered now we have few coding questions that can flesh out our learning of pytorch in general.\n",
    "\n",
    "<ol>\n",
    "    <li>Given two tensors 'a' and 'b', write a code snippet to perform element-wise addition of the two tensors and store the result in a new tensor c. Print the resulting tensor 'c'. \n",
    "        <ul>\n",
    "            <li> Same length Tensors </li>\n",
    "            <li> Different Length Tensors </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output same length tensors : [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "#For Same length: \n",
    "a=torch.ones(5).type(torch.int16)\n",
    "b=torch.arange(0,5).type(torch.int16)\n",
    "c=a+b \n",
    "print(f'output same length tensors : {c.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([3, 1, 9, 2, 9, 7, 6, 0])\n",
      "Tensor B: tensor([8, 3, 9, 1, 2, 0, 9, 8])\n",
      "Torch C: tensor([11,  4, 18,  3, 11,  7, 15,  8], dtype=torch.int32)\n",
      "Execution Time: 2.0189285278320312 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#For different length: \n",
    "t_s=time.time()\n",
    "\n",
    "a=torch.tensor([random.randrange(0,10) for i in range(0,random.randrange(5,25))])\n",
    "b=torch.tensor([random.randrange(0,10) for i in range(0,random.randrange(1,10))])\n",
    "\n",
    "print(f'Tensor A: {a}')\n",
    "print(f'Tensor B: {b}')\n",
    "\n",
    "a=a.tolist()\n",
    "b=b.tolist()\n",
    "\n",
    "\n",
    "range_val=max([len(a),len(b)])\n",
    "c=[]\n",
    "for i in range(range_val):\n",
    "    try:\n",
    "        c.append(a[i]+b[i])\n",
    "    except:\n",
    "        try:\n",
    "            c.append(a[i])\n",
    "        except:\n",
    "            c.append(b[i])\n",
    "\n",
    "print(f'Torch C: {torch.from_numpy(np.array(c))}')\n",
    "t_e=time.time()\n",
    "print(f'Execution Time: {(t_e-t_s)*1000} ms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
