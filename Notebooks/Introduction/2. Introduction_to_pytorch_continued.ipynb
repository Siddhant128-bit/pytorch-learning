{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tensor Data types </h3>\n",
    "\n",
    "Tensors are pretty confusing to deal with at first because there are many different types of tensor datatypes in pytorch <br>\n",
    "Some are specific to CPU other are better for GPU <br>\n",
    "\n",
    "Tensors also have bits as torch.float32 torch.float16 torch.float8 and so on.<br>\n",
    "In simplest understanding term we can understand that higher bit or precision value means more detail can be obtained and carried over <br>\n",
    "but are comparatively slower then lower precision value <br>\n",
    "\n",
    "Some major issues we come across while handling tensors are: \n",
    "<ol>\n",
    "    <li> datatype issue where the 2 tensors won't have same datatype format (float32 and float16) </li>\n",
    "    <li> device issue where the tensor is deisgned to work on CPU and other is designated to work for GPU </li>\n",
    "</ol>\n",
    "\n",
    "Below we can observe different tensor types with precision values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3246, 0.5534, 0.1123]) torch.float32 cpu\n",
      "tensor([0.3245, 0.5532, 0.1124], dtype=torch.float16) torch.float16 cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "float_32_tensor=torch.tensor([0.3245671892,0.55341245,0.11234153],dtype=torch.float32,device=None,requires_grad=False)\n",
    "print(float_32_tensor,float_32_tensor.dtype,float_32_tensor.device)\n",
    "\n",
    "float_16_tensor=torch.tensor([0.3245671892,0.55341245,0.11234153],dtype=torch.float16,device=None,requires_grad=False)\n",
    "print(float_16_tensor,float_16_tensor.dtype,float_16_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Matrix Multiplication </h3>\n",
    "\n",
    "We can easily say that matrix multiplication is the backbone of neural network architechture, <br>\n",
    "Since we have multiple  neurons with their own weights and biases resulting in structures having alot of outputs with many more operations which be optimized by using matrix multiplication<br>\n",
    "<br>\n",
    "PyTorch implements matrix multiplication functionality in the torch.matmul() or torch.mm() method.\n",
    "\n",
    "<h4> Rule for Matrix Multiplication: </h4>\n",
    "<img width=800 height=500 src='https://i.ytimg.com/vi/M5TsRZt3mis/maxresdefault.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matirx A: \n",
      " tensor([[2., 1.],\n",
      "        [1., 2.]]) \n",
      " Dimension of Matrix A: \n",
      " torch.Size([2, 2])\n",
      "\n",
      "\n",
      "\n",
      "Matirx B: \n",
      " tensor([[3., 1., 5.],\n",
      "        [2., 2., 3.]]) \n",
      " Dimension of Matrix B: \n",
      " torch.Size([2, 3])\n",
      "\n",
      "\n",
      "\n",
      "Output Matrix: \n",
      " tensor([[ 8.,  4., 13.],\n",
      "        [ 7.,  5., 11.]])\n",
      " Dimension of Output Matrix: \n",
      " torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "Matrix_A=torch.tensor(np.asarray([[2,1],\n",
    "                                [1,2]]),dtype=torch.float32)\n",
    "\n",
    "Matrix_B=torch.tensor(np.asarray([[3,1,5],\n",
    "                                  [2,2,3]]),dtype=torch.float32)\n",
    "\n",
    "print(f'Matirx A: \\n {Matrix_A} \\n Dimension of Matrix A: \\n {Matrix_A.shape}')\n",
    "print('\\n\\n')\n",
    "print(f'Matirx B: \\n {Matrix_B} \\n Dimension of Matrix B: \\n {Matrix_B.shape}')\n",
    "print('\\n\\n')\n",
    "\n",
    "Output_Matrix=torch.matmul(Matrix_A,Matrix_B)\n",
    "print(f'Output Matrix: \\n {Output_Matrix}\\n Dimension of Output Matrix: \\n {Output_Matrix.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Transpose of Matrix </h3>\n",
    "\n",
    "<p>Transpose of a matrix is one of the most commonly used methods in matrix transformation. For a given matrix, the transpose of a matrix is obtained by interchanging rows into columns or columns to rows. <br> It can be done for purpose of preparing matrix for matrix multiplication, finding out inverse of a matrix and many more. </p>\n",
    "\n",
    "<img  align='left' height=300 width=800 src='https://cdn1.byjus.com/wp-content/uploads/2021/09/Important-Questions-for-Class-10-Maths-Chapter-8-Introduction-to-Trigonometry-1.png'>\n",
    "\n",
    "<p>\n",
    "    &nbsp;&nbsp;Matrix Tranpose can be done on pytorch with<br>\n",
    "    <ol>\n",
    "        <li> 1.  ''' torch.tranpose(input,dim0,dim1) ''' : where input is desired tensor to tranpose and dim0 and dim1 are the dimension to be swapped.</li><br>\n",
    "        <li> 2.  ''' tensor.T ''' : where tensor is the desired tensor to tranpose.</li>\n",
    "    <ol>\n",
    "</p>\n",
    "<br><br><br><br><br><br>\n",
    "<h4 align='left'> Example</h4>\n",
    " Assuming we have a matrix A as shown in the figure above: <br>\n",
    " A=[[1,2,3],<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    [4,5,6]]\n",
    "<br><br>\n",
    "B=[[7,8], <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "   [9,10]]\n",
    "\n",
    "As it stands right now A has dimensions as: 2x3 and B has dimensions as: 2x2 \n",
    "right now the 2 cannot be multiplied. Solve it: \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      "\n",
      "Dimensions: torch.Size([2, 3]) \n",
      "--------------------------------------------------\n",
      "Matrix A Transposed:\n",
      " tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]]) \n",
      "\n",
      "Dimensions: torch.Size([3, 2])\n",
      "--------------------------------------------------\n",
      "Matrix Multiplication Output:\n",
      " tensor([[43., 48.],\n",
      "        [59., 66.],\n",
      "        [75., 84.]]) \n",
      "\n",
      " Dimension of Output: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor(np.asarray([[1,2,3],\n",
    "                           [4,5,6]]),dtype=torch.float32,device=None, requires_grad=False)\n",
    "\n",
    "print(f'Matrix A:\\n {A} \\n\\nDimensions: {A.shape} ')\n",
    "\n",
    "#Getting Transpose to change dimensions from 2,3 to 3,2 which makes it possible to have matrix multplication with B having 2x2 resulting in output of 3,2 dimension\n",
    "A=A.T\n",
    "\n",
    "print('-'*50)\n",
    "print(f'Matrix A Transposed:\\n {A} \\n\\nDimensions: {A.shape}')\n",
    "print('-'*50)\n",
    "\n",
    "B=torch.tensor(np.asarray([[7,8],\n",
    "                            [9,10]]),dtype=torch.float32,device=None,requires_grad=False)\n",
    "\n",
    "output=torch.matmul(A,B)\n",
    "\n",
    "print(f'Matrix Multiplication Output:\\n {output} \\n\\n Dimension of Output: {output.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
